{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of datasets\n",
    "data_list = ['christensen', 'sun', 'alon', 'nakayama', 'tian', 'chin', 'chowdary', \n",
    "             'subramanian', 'chiaretti', 'golub', 'shipp', 'su', 'gordon', 'khan', \n",
    "             'singh', 'gravier', 'borovecki', 'sorlie', 'west']\n",
    "\n",
    "wrapper_list = ['Decision Tree', 'k-Nearest Neighbor', 'Naive Bayes', 'Support Vector Machine']\n",
    "\n",
    "# Path to the folder containing data files\n",
    "PATH_TEST = '/Users/erirosv/fun/Master-Thesis/plotting-result/version2/merged-data'\n",
    "p = os.path.abspath(PATH_TEST)\n",
    "\n",
    "datasets = []\n",
    "for d in data_list:\n",
    "    csv_files = glob.glob(os.path.join(p, f'results_{d}.csv'))\n",
    "    for csv_file in csv_files:\n",
    "        dataset = pd.read_csv(csv_file)\n",
    "        dataset['score_mean'] = 100 * (1 - pd.to_numeric(dataset['cv_error_mean'], errors='coerce'))\n",
    "        datasets.append(dataset)  # Append the dataset to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert a value to accuracy percentages\n",
    "def convert_to_accuracy_percentages(x):\n",
    "    return (100 * (1 - x))\n",
    "\n",
    "# Calculate method results for each classifier\n",
    "def calculate_method_results(data, col_names):\n",
    "    method_results = {}\n",
    "    for col_name in col_names:\n",
    "        if col_name == 'num_features_algo' or col_name == '_wrapper' or col_name == 'score_mean':\n",
    "            continue\n",
    "        if col_name == 'CFS':\n",
    "            continue  # Skip 'CFS' column\n",
    "        method_results[col_name] = data.pivot(index='num_features_algo', columns='_wrapper', values=col_name)\n",
    "    return method_results\n",
    "\n",
    "# Define the column names to calculate results\n",
    "col_names = ['CFS', 'FScore', 'GA', 'InfoGain', 'MRMR', 'ReliefF', 'SFS', 'SPFSR', 'RFI']\n",
    "\n",
    "datasets[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets[0]\n",
    "test.head()\n",
    "\n",
    "ds_name = set()\n",
    "for dataset in datasets:\n",
    "    for d in dataset['dataset']:\n",
    "        ds_name.add(d)\n",
    "unique_ds_names = list(ds_name)\n",
    "\n",
    "col_names = []\n",
    "for d in test.columns:\n",
    "    if 'cv_' in d or d in ['num_features_algo', '_wrapper', 'score_mean']:\n",
    "        col_names.append(d)\n",
    "\n",
    "ds_feature = set()\n",
    "for dataset in datasets:\n",
    "    for d in dataset['num_features_algo']:\n",
    "        ds_feature.add(d)\n",
    "unique_ds_features = list(ds_feature)\n",
    "\n",
    "unique_folders = datasets[0]['dataset'].unique()\n",
    "unique_classifiers = datasets[0]['_wrapper'].unique()\n",
    "\n",
    "print('----- TEST values -----')\n",
    "print(unique_folders)\n",
    "print(unique_classifiers)\n",
    "print('----- Actual values -----')\n",
    "print(f'Dataset Names: {unique_ds_names}')\n",
    "print(f'Column Names: {col_names}')\n",
    "print(f'Features: {unique_ds_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_DT = []\n",
    "matching_SVM = []\n",
    "matching_NB = []\n",
    "matching_KNN = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    if '_wrapper' in dataset.columns and 'DT' in dataset['_wrapper'].values:\n",
    "        dt_rows = dataset[dataset['_wrapper'] == 'DT']\n",
    "        matching_DT.append(dt_rows)\n",
    "\n",
    "    if '_wrapper' in dataset.columns and 'SVM' in dataset['_wrapper'].values:\n",
    "        dt_rows = dataset[dataset['_wrapper'] == 'SVM']\n",
    "        matching_SVM.append(dt_rows)\n",
    "\n",
    "    if '_wrapper' in dataset.columns and 'NB' in dataset['_wrapper'].values:\n",
    "        dt_rows = dataset[dataset['_wrapper'] == 'NB']\n",
    "        matching_NB.append(dt_rows)\n",
    "\n",
    "    if '_wrapper' in dataset.columns and 'KNN' in dataset['_wrapper'].values:\n",
    "        dt_rows = dataset[dataset['_wrapper'] == 'KNN']\n",
    "        matching_KNN.append(dt_rows)\n",
    "\n",
    "DT = pd.concat(matching_DT, ignore_index=True)\n",
    "SVM = pd.concat(matching_SVM, ignore_index=True)\n",
    "NB = pd.concat(matching_NB, ignore_index=True)\n",
    "KNN = pd.concat(matching_KNN, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_method_results(dataframe):\n",
    "    method_results = {}\n",
    "\n",
    "    # Calculate the mean for 'num_features_algo', 'score_mean', and 'fs_method'\n",
    "    method_results['num_features_algo'] = dataframe.groupby(['dataset', 'num_features_algo'])['score_mean'].mean().reset_index()\n",
    "    \n",
    "    # Remove duplicates from '_wrapper' column and save it in a separate key\n",
    "    method_results['_wrapper'] = dataframe.drop_duplicates(['dataset', '_wrapper'])[['_wrapper']]\n",
    "    \n",
    "    # Calculate the mean for 'score_mean' without grouping by '_wrapper'\n",
    "    method_results['score_mean'] = dataframe.groupby(['dataset'])['score_mean'].mean().reset_index()\n",
    "    \n",
    "    # Assuming 'fs_method' is a column in the dataframe, calculate its mean\n",
    "    method_results['fs_method'] = dataframe.groupby(['dataset', 'fs_method'])['score_mean'].mean().reset_index()\n",
    "\n",
    "    return method_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_result_DT = calculate_method_results(DT)\n",
    "method_result_NB = calculate_method_results(NB)\n",
    "method_result_SVM = calculate_method_results(SVM)\n",
    "method_result_KNN = calculate_method_results(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(method_result_DT.keys())\n",
    "print()\n",
    "print(method_result_DT.items())\n",
    "print()\n",
    "print(method_result_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_styles = ['-', '--', '-.', ':', '-', '--', '-.', ':', '-']\n",
    "markers = ['o', 's', 'D', 'X', '^', 'v', '<', '>', '+']\n",
    "\n",
    "classifiers = ['DT', 'KNN', 'NB', 'SVM']\n",
    "classifier_dataframes = [DT, KNN, NB, SVM]\n",
    "\n",
    "new_folder_name = \"acc_num_feature\"\n",
    "current_folder = os.getcwd()\n",
    "new_folder_path = os.path.join(current_folder, new_folder_name)\n",
    "if not os.path.exists(new_folder_path):\n",
    "    os.makedirs(new_folder_path)\n",
    "\n",
    "for classifier, dataframe in zip(classifiers, classifier_dataframes):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    print(classifier)\n",
    "    classifier_df = dataframe[dataframe['_wrapper'] == classifier]\n",
    "    custom_palette = sns.color_palette(\"husl\", len(classifier_df['fs_method'].unique()))\n",
    "\n",
    "    for i, (fs_method, fs_method_data) in enumerate(classifier_df.groupby('fs_method')):\n",
    "        sns.lineplot(\n",
    "            data=fs_method_data, x='num_features_algo', y='score_mean',\n",
    "            label=fs_method, linestyle=line_styles[i % len(line_styles)], marker=markers[i % len(markers)],\n",
    "            color=custom_palette[i],  \n",
    "            errorbar=None  \n",
    "        )\n",
    "\n",
    "    FONT_SIZE = 28\n",
    "    custom_ticks = [5, 10, 15, 20, 25]\n",
    "    plt.xlabel('Number of Selected Features', fontsize=FONT_SIZE)\n",
    "    plt.ylabel('Accuracy (%)', fontsize=FONT_SIZE)\n",
    "    plt.title(f'{classifier}', fontsize=FONT_SIZE + 2)\n",
    "    plt.xticks(custom_ticks, labels=custom_ticks)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=FONT_SIZE - 16)\n",
    "\n",
    "    plot_filename_png = f\"{classifier}_plot.png\"\n",
    "    plot_filepath_png = os.path.join(new_folder_path, plot_filename_png)\n",
    "    plt.savefig(plot_filepath_png, format='png', dpi=300)\n",
    "\n",
    "    plot_filename_eps = f\"{classifier}_plot.eps\"\n",
    "    plot_filepath_eps = os.path.join(new_folder_path, plot_filename_eps)\n",
    "    plt.savefig(plot_filepath_eps, format='eps', dpi=300)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
