{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import numpy as np \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = pd.DataFrame()\n",
    "KNN = pd.DataFrame()\n",
    "SVM = pd.DataFrame()\n",
    "NB = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_accuracy_percentages(x):\n",
    "    return (100*(1-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of datasets\n",
    "data_list = ['christensen', 'sun', 'alon', 'nakayama', 'tian', 'chin', 'chowdary', \n",
    "             'subramanian', 'chiaretti', 'golub', 'shipp', 'su', 'gordon', 'khan', \n",
    "             'singh', 'gravier', 'borovecki', 'sorlie', 'west', 'yeoh', 'burczynski',\n",
    "             'pomeroy']\n",
    "\n",
    "wrapper_list = ['Decision Tree', 'k-Nearest Neighbor', 'Naive Bayes', 'Support Vector Machine']\n",
    "\n",
    "# Path to the folder containing data files\n",
    "PATH_TEST = '/Users/erirosv/fun/Master-Thesis/plotting-result/plots_v2/data_v2'\n",
    "p = os.path.abspath(PATH_TEST)\n",
    "\n",
    "datasets = []\n",
    "for d in data_list:\n",
    "    csv_files = glob.glob(os.path.join(p, f'results_{d}.csv'))\n",
    "    for csv_file in csv_files:\n",
    "        dataset = pd.read_csv(csv_file)\n",
    "        dataset['score_mean'] = 100 * (1 - pd.to_numeric(dataset['cv_error_mean'], errors='coerce'))\n",
    "        datasets.append(dataset)  # Append the dataset to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert a value to accuracy percentages\n",
    "def convert_to_accuracy_percentages(x):\n",
    "    return (100 * (1 - x))\n",
    "\n",
    "# Calculate method results for each classifier\n",
    "def calculate_method_results(data, col_names):\n",
    "    method_results = {}\n",
    "    for col_name in col_names:\n",
    "        if col_name == 'num_features_algo' or col_name == '_wrapper' or col_name == 'score_mean':\n",
    "            continue\n",
    "        if col_name == 'CFS':\n",
    "            continue  # Skip 'CFS' column\n",
    "        method_results[col_name] = data.pivot(index='num_features_algo', columns='_wrapper', values=col_name)\n",
    "    return method_results\n",
    "\n",
    "\n",
    "# Define the column names to calculate results\n",
    "col_names = ['CFS', 'FScore', 'GA', 'InfoGain', 'MRMR', 'ReliefF', 'SFS', 'SPFSR', 'RFI']\n",
    "\n",
    "datasets[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_unique_names = pd.concat(datasets, ignore_index=True)\n",
    "unique_datasets = combined_df_unique_names['dataset'].unique()\n",
    "print(unique_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets[0]\n",
    "test.head()\n",
    "\n",
    "ds_name = set()\n",
    "for dataset in datasets:\n",
    "    for d in dataset['dataset']:\n",
    "        ds_name.add(d)\n",
    "unique_ds_names = list(ds_name)\n",
    "\n",
    "col_names = []\n",
    "for d in test.columns:\n",
    "    if 'cv_' in d or d in ['num_features_algo', '_wrapper', 'score_mean']:\n",
    "        col_names.append(d)\n",
    "\n",
    "ds_feature = set()\n",
    "for dataset in datasets:\n",
    "    for d in dataset['num_features_algo']:\n",
    "        ds_feature.add(d)\n",
    "unique_ds_features = list(ds_feature)\n",
    "\n",
    "unique_folders = datasets[0]['dataset'].unique()\n",
    "unique_classifiers = datasets[0]['_wrapper'].unique()\n",
    "\n",
    "print('----- TEST values -----')\n",
    "print(unique_folders)\n",
    "print(unique_classifiers)\n",
    "print('----- Actual values -----')\n",
    "print(f'Dataset Names: {unique_ds_names}')\n",
    "print(f'Column Names: {col_names}')\n",
    "print(f'Features: {unique_ds_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_DT = []\n",
    "matching_SVM = []\n",
    "matching_NB = []\n",
    "matching_KNN = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    if '_wrapper' in dataset.columns and 'DT' in dataset['_wrapper'].values:\n",
    "        dt_rows = dataset[dataset['_wrapper'] == 'DT']\n",
    "        matching_DT.append(dt_rows)\n",
    "\n",
    "    if '_wrapper' in dataset.columns and 'SVM' in dataset['_wrapper'].values:\n",
    "        dt_rows = dataset[dataset['_wrapper'] == 'SVM']\n",
    "        matching_SVM.append(dt_rows)\n",
    "\n",
    "    if '_wrapper' in dataset.columns and 'NB' in dataset['_wrapper'].values:\n",
    "        dt_rows = dataset[dataset['_wrapper'] == 'NB']\n",
    "        matching_NB.append(dt_rows)\n",
    "\n",
    "    if '_wrapper' in dataset.columns and 'KNN' in dataset['_wrapper'].values:\n",
    "        dt_rows = dataset[dataset['_wrapper'] == 'KNN']\n",
    "        matching_KNN.append(dt_rows)\n",
    "\n",
    "DT = pd.concat(matching_DT, ignore_index=True)\n",
    "SVM = pd.concat(matching_SVM, ignore_index=True)\n",
    "NB = pd.concat(matching_NB, ignore_index=True)\n",
    "KNN = pd.concat(matching_KNN, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_methods_name = list(DT['fs_method'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_fs_methods = combined_df_unique_names['fs_method'].unique()\n",
    "print(unique_fs_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different line styles and markers\n",
    "line_styles = ['-', '--', '-.', ':', '-', '--', '-.', ':', '-']\n",
    "markers = ['o', 's', 'D', 'X', '^', 'v', '<', '>', '+', '*']\n",
    "\n",
    "# List of classifiers and their corresponding dataframes\n",
    "classifiers = ['DT', 'KNN', 'NB', 'SVM']\n",
    "classifier_dataframes = [DT, KNN, NB, SVM]\n",
    "\n",
    "# Create a new folder for saving the plots\n",
    "new_folder_name = \"FINAL_VERSION_INDIVIDUAL\"\n",
    "current_folder = os.getcwd()\n",
    "new_folder_path = os.path.join(current_folder, new_folder_name)\n",
    "if not os.path.exists(new_folder_path):\n",
    "    os.makedirs(new_folder_path)\n",
    "\n",
    "# Define the classifiers and methods to plot\n",
    "classifiers = unique_classifiers\n",
    "methods = unique_fs_methods\n",
    "\n",
    "# Iterate through each dataset\n",
    "for dataset_name in data_list:\n",
    "    for i, (classifier, dataframe) in enumerate(zip(classifiers, classifier_dataframes)):\n",
    "        classifier_df = dataframe[dataframe['_wrapper'] == classifier]\n",
    "\n",
    "        # Create a figure for the current dataset and classifier\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "        # Define a custom color palette with distinct colors for each fs_method\n",
    "        custom_palette = sns.color_palette(\"husl\", len(classifier_df['fs_method'].unique()))\n",
    "\n",
    "        # Iterate through each fs_method\n",
    "        for j, (fs_method, fs_method_data) in enumerate(classifier_df.groupby('fs_method')):\n",
    "            # Filter the data for the current dataset\n",
    "            if fs_method == 'PCA':\n",
    "                continue  # Skip plotting 'PCA'\n",
    "            dataset_data = fs_method_data[fs_method_data['dataset'] == dataset_name]\n",
    "\n",
    "            # Plot the data for the current fs_method with custom line style, marker, and color\n",
    "            sns.lineplot(\n",
    "                data=dataset_data, x='num_features_algo', y='score_mean',\n",
    "                label=fs_method, linestyle=line_styles[j % len(line_styles)], marker=markers[j % len(markers)],\n",
    "                color=custom_palette[j],  # Use a distinct color from the custom palette\n",
    "                ci=None,\n",
    "                ax=ax\n",
    "            )\n",
    "        FONT_SIZE = 28\n",
    "        # Set plot labels and title\n",
    "        ax.set_xlabel('Number of Selected Features', fontsize=FONT_SIZE)\n",
    "        ax.set_ylabel('Accuracy (%)', fontsize=FONT_SIZE)\n",
    "        ax.set_title(f'{classifier} - {dataset_name}', fontsize=FONT_SIZE + 2)\n",
    "\n",
    "        # Add a legend to the plot\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=FONT_SIZE - 16)\n",
    "\n",
    "        # Set custom x-axis ticks and labels\n",
    "        custom_ticks = [5, 10, 15, 20, 25]\n",
    "        ax.set_xticks(custom_ticks)\n",
    "        ax.set_xticklabels(custom_ticks)\n",
    "\n",
    "        # Save the individual plot for the dataset and classifier as .png and .eps\n",
    "        plot_filename = f\"{dataset_name}_{classifier}_plot\"\n",
    "        plot_filepath_png = os.path.join(new_folder_path, f\"{plot_filename}.png\")\n",
    "        plot_filepath_eps = os.path.join(new_folder_path, f\"{plot_filename}.eps\")\n",
    "        fig.savefig(plot_filepath_png, format='png', dpi=300, bbox_inches='tight')\n",
    "        fig.savefig(plot_filepath_eps, format='eps', dpi=300, bbox_inches='tight')\n",
    "\n",
    "        # Show and close the plot to release resources\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
